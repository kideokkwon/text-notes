{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsLSR+k1SI/uYQvFFyY4jR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1: A Definition of Causal Effect"
      ],
      "metadata": {
        "id": "F_uvsHE4HfTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Individual Causal Effects"
      ],
      "metadata": {
        "id": "Z_Jpjtx3LoDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A formal definition of a *causal effect for an individual*:\n",
        "\n",
        "The Treatment $A$ has a causal effect on an individual's outcome $Y$ if:\n",
        "$$Y^{a=1}\\neq Y^{a=0}$$\n",
        "\n",
        "Let $Y^{a=1}$ (read $Y$ under treatment $a=1$) be the outcome variable that would have been observed under treatment value $a=1$, and is referred to as a *potential outcome* or a *counterfactual outcome*.\n",
        "\n",
        "The *consistency* assumption is that if an individual's *potential outcome* for treatment $a=1$ is $Y^{a=1}=1$, if a user actually does get treatment ($a=1$) then the realized outcome is $Y=1$.\n",
        "\n",
        "This can be written as:\n",
        "$$\\text{if }A_i=a,\\text{ then }Y_i^a=Y_i^A=Y_i$$\n",
        "\n",
        "We also assume that an individual's counterfactual outcome under treatment value $a$ does not depend on other individual's treatment values (For example, interference would be if person $j$'s treatment influences person $k$'s outcome). The assumption of no interference is labeled \"no interaction between units\" and is included in the \"stable-unit-treatment-value assumption\" (SUTVA) described by Rubin (1980). This book assumes no interference unless otherwise specified."
      ],
      "metadata": {
        "id": "DCzF-0k1Lq4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Average Causal Effects"
      ],
      "metadata": {
        "id": "G7E07AqZMFzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formal definition of the *average causal effect*:\n",
        "\n",
        "An average causal effect of treatment $A$ on outcome $Y$ is present if\n",
        "$$E[Y^{a=1}]\\neq E[Y^{a=0}]$$\n",
        "\n",
        "Note that the definitions above also implicitly assume that treatment is dichotomous.\n",
        "\n",
        "If there is no causal effect for any individual in the population, i.e., $Y^{a=1}=Y^{a=0}$ for all individuals, we say that the *sharp causal null hypothesis* is true.\n",
        "\n",
        "Since individual causal effects cannot be identified, we always focus on *average* causal effect."
      ],
      "metadata": {
        "id": "UKa8X6evMG2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Measures of Causal Effect"
      ],
      "metadata": {
        "id": "xGB5Td4iMG4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are numerous ways to represent the causal null:\n",
        "\n",
        "- (i) Risk Difference: $P[Y^{a=1}=1]-P[Y^{a=0}=1]=0$\n",
        "- (ii) Risk Ratio: $\\frac{P[Y^{a=1}=1]}{P[Y^{a=0}=1]}=1$\n",
        "- (iii) Odds Ratio: $\\frac{P[Y^{a=1}=1]/P[Y^{a=1}=0]}{P[Y^{a=0}=1]/P[Y^{a=0}=0]}=1$\n",
        "\n",
        "Note that for rare events, the odds ratio becomes pretty close to the risk ratio.\n",
        "\n",
        "Because the causal risk difference, risk ratio, and odds ratio (and other summaries) measure the causal effect, we refer to them as *effect measures*."
      ],
      "metadata": {
        "id": "soX56cxxMG7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Random Variability"
      ],
      "metadata": {
        "id": "5wiN4T0jULdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We say that $\\hat{P}[Y^a=1]$ is a *consistent estimator* of $P[Y^a=1]$ because the larger number of individuals in the sample, the smaller the difference between the two is expected to be. This occurs because the error due to sampling variability is random and thus obeys the laws of large numbers.\n",
        "\n",
        "In causal inference, random error derives from sampling variability and nondeterministic counterfactuals, or both. Intuitively, an example of a nondeterministic counterfactual would be if an individual has a 90% chance of $Y=1$ if $A=1$ as opposed to 100%."
      ],
      "metadata": {
        "id": "vHSGzbX6ULgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Causation Versus Association"
      ],
      "metadata": {
        "id": "Aba6nYjDdFpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the proportion of individuals who develop the outcome in the treated $P(Y=1|A=1)$ equals the proportion of individuls who develop the outcome in the untreated $P(Y=1|A=0)$, we say that $A\\perp Y$, read as $A$ and $Y$ are independent.\n",
        "\n",
        "Some equivalent definitions of independence are\n",
        "\n",
        "- (i) Associational risk difference: $P[Y=1|A=1]-P[Y=1|A=0]=0$\n",
        "\n",
        "As well as the associational risk ratio and odds ratio."
      ],
      "metadata": {
        "id": "NSgaLvVkdFrf"
      }
    }
  ]
}