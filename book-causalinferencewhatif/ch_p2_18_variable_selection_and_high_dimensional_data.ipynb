{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKvPeeTLQu4MbTa/nzrYGU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 18: Variable Selection and High-Dimensional Data"
      ],
      "metadata": {
        "id": "cPhCKZ3MLKHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chapter summarizes the problems of incorrect variable selection in causal analyses and outlines some practical guidance."
      ],
      "metadata": {
        "id": "kZ_NwQSgLKJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 18.1 The different goals of variable selection"
      ],
      "metadata": {
        "id": "QjgGyT9LLKMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable selection for prediction is fundamentally different from causal analyses. In prediction, we just want to make better prediction - we do not care if the variables are confounders or not as long as it improves predictive strength. For example, prior hospitalization may help predict future heart failure, but we would not sugguest to stop admitting people to the hospital in order to prevent heart failures."
      ],
      "metadata": {
        "id": "TxpygBpuLnEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 18.2 Variables that induce or amplify bias"
      ],
      "metadata": {
        "id": "O9pVObqDLnHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colliders induce bias when controlling for it. Unfortunately, even whengiven the temporal ordering of $A,L,Y$, we cannot determine from the data whether or not $A$ affects $L$. Thus the decision to adjust for $L$ must be based on information outside of the data.\n",
        "\n",
        "There is also a concept called $Z$-bias where controlling for an instrument can *amplify* the bias of unobserved confounding, referred to as *bias amplification*."
      ],
      "metadata": {
        "id": "HhsJNaALLnJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 18.3 Causal inference and macine learning"
      ],
      "metadata": {
        "id": "guDXERiINXiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say that controlling for a set of variables $X$ will not induce or amplify bias.\n",
        "\n",
        "Our next problem is the problem of high-dimensionality or multiple continuous variables.\n",
        "\n",
        "We can try using prediction-esque algorithms such as lasso and ridge regression, however, by themselves they do not suffice to adequately adjust for confounding in high-dimensional settings. These algorithms must be used in conjunction with doubly robust estimators with two modifications:\n",
        "- sample splitting\n",
        "- cross-fitting\n",
        "\n",
        "This is necessary if we hope to construct valid 95% Wald confidence intervals (i.e., intervals that trap the causal parameter of interest at least 95% of the time)."
      ],
      "metadata": {
        "id": "0VictcWRNXlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 18.4 Doubly robust machine learning estimators"
      ],
      "metadata": {
        "id": "-czYjWRTLnKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through sample splitting and cross-fitting, we can combine doubly robust estimation and machine learning to obtain causal effect estimates which have known statistical properties and which use all the available data.\n",
        "\n",
        "An active research area is the development of procedures to detect whether the bias of doubly robust split-sample estimators is the order of or larger than the standard error."
      ],
      "metadata": {
        "id": "46CzrGqtSn_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 18.5 Variable selection is a difficult problem"
      ],
      "metadata": {
        "id": "wctyFuKRSoBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combination of causal inference methods with machine learning algorithms for confounder selection can, under certain conditions, result in correct statistical inference. However, doubly robust machine learning does not solve all our problems for at least 3 reasons.\n",
        "\n",
        "First, the available subject-matter knowledge may be insufficient to identify all important confounders.\n",
        "\n",
        "Second, the implementation has been difficult and computationally expensive.\n",
        "\n",
        "Third, there is no guarantee that the variance given by the estimation will be small enough for meaningful causal inference.\n",
        "\n"
      ],
      "metadata": {
        "id": "th-ONpXNTYod"
      }
    }
  ]
}