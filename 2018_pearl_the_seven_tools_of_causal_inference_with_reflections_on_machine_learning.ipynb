{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyGjjsVSDYAh/tj8HhPQgI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# (Pearl, 2018) The Seven Tools of Causal Inference with Reflections on Machine Learning"
      ],
      "metadata": {
        "id": "IjmmlNN8RNtX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Some quick notes from Pearl's brief summary of the current innovation in Causal Inference, from his point of view.*"
      ],
      "metadata": {
        "id": "jSvWJgYdd4v1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ftp.cs.ucla.edu/pub/stat_ser/r481.pdf"
      ],
      "metadata": {
        "id": "5JITX_pzRNvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dramatic success in machine learning has led to increasing expectations of autonomous systems that exhibit human-level intelligence.\n",
        "\n",
        "However, there are several fundamental obstacles\n",
        "1. *adaptability* or *robustness*: current systems lack the capability of recognizing or reacting to new circumstances they have not been specifically programmed for.\n",
        "2. *explanability*: machine learning models remain mostly black boxes\n",
        "3. understanding the *cause-effect connections*, which is a necessary ingredient for achieving human-level intelligence (the paper claims that this is an opinion of the author). This when solved would allow machines to answer \"What If?\" kind of questions as well as \"What if I make it happen?\", \"What if I had acted differently?\".\n",
        "\n",
        "Next, the author describes a 3-level hierarchy that restricts and governs inferences in causal reasoning. Then, the author summarizes how traditional impediments are circumvented using modern tools of causal inference (7 of them!)\n",
        "\n"
      ],
      "metadata": {
        "id": "m7AIYrTtRNyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Three Layer Causal Hierarchy"
      ],
      "metadata": {
        "id": "TcmiKbliRY9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 3 layer classification unveils the kind of questions that each class is capable of answering. The levels are:\n",
        "1. *Association* $P(y|x)$: purely statistical relationships. The hallmark of current ML methods.\n",
        "2. *Intervention* $P(y|do(x),z)$: e.g., \"What will happen if we double the price?\". can be estimated experimentally from randomized trials or analytically using causal bayesian networks\n",
        "3. *Counterfactual* $P(y_x|x',y')$: e.g., \"What if I had acted differently?\", thus necessitating retrospective reasoning.\n",
        "\n",
        "Counterfactuals are at the top because they subsume interventional and associational questions.\n",
        "\n",
        "The expression $P(y_x|x',y')$ stands for \"The probability that event $Y=y$ would be oserved had $X$ been $x$, given that we actually observed $X$ to be $x'$ and $Y$ to be $y'$. For example, the probability that Joe's salary would be $y$ had he finished college, given that his actual salary is $y'$ and that he had only two years of college. Such sentences can be computed only when we possess functional or Structural Equation models, or properties of such models.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ClEwHIRqRY_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Seven Tools of Causal Inference (Or what you Can Do With a Causal Model that you could not do without?)"
      ],
      "metadata": {
        "id": "ESUwgqU8RZCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The author mentions that questions involving \"cause\", \"attributed to\", \"preventing\", etc., all causal questions, until recently science gave us no means even to articulate them, let alone answer them. The author further claims that only a few decades ago scientists were unable to write down a mathematical equation for the obvious fact that \"mud does not cause rain\".\n",
        "\n",
        "In the past 3 decades, a mathematical langauge has been developed for managing causes and effects, accompanied by a set of tools that turn causal analysis into a mathematical game, like solving algebraic equations.\n",
        "\n",
        "The author calls this mathematical framework that led to this transformation as \"Structural Causal Models (SCM)\", which deploys in 3 parts:\n",
        "1. Graphical models\n",
        "2. Structural Equations\n",
        "3. Counterfactual and Interventional logic\n",
        "\n",
        "Graphical models serve as a language for representing what we know about the world, counterfactuals help us articulate what we want to know, while structural equations serve to tie the two together in a solid semantics.\n",
        "\n",
        "In addition, there is an \"inference engine\" that takes as input:\n",
        "- Query\n",
        "- Assumptions (i.e., graphical model)\n",
        "- Data\n",
        "\n",
        "and outputs:\n",
        "- Estimand ($E_S$)\n",
        "- Estimate ($\\hat E_S$)\n",
        "- Fit Indices ($F$)\n",
        "\n",
        "For example, let's assume that we have a query of the causal effect of $X$ on $Y$:\n",
        "$$Q=P(Y|do(X))$$\n",
        ", with a confounder $Z$.\n",
        "\n",
        "Finally, let the data be sampled at random from a joint distribution $P(X,Y,Z)$. The estimand ($E_S$) will be the formula:\n",
        "$$E_S=\\sum_Z P(Y|X,Z)P(Z)$$\n",
        ", which defines a procedure of estimation.\n",
        "\n",
        "The actual Estimate $\\hat E_S$ can be produced by any number of techniques that produce a consistent estimate of $E_S$ from finite samples of $P(X,Y,Z)$.\n",
        "\n",
        "Finally, the Fit index will be NULL. In other words, after examining the structure of the graph, the engine should conclude that the assumption encoded do not have any testable implications. Therefore, the veracity of the resultant estimate must lean entirely on the assumptions encoded in the graph.\n",
        "\n",
        "Efficient and complete algorithms have been developed to decide identifiability and produce estimands for a variety of counterfactual queries and a variety of data types."
      ],
      "metadata": {
        "id": "DZlukS6gVleq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool 1: Encoding Causal Assumptions - Transparency and Testability"
      ],
      "metadata": {
        "id": "UVb2TGZ0Vlg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transparency enables analysts to discern whether the assumptions encoded are plausible, or whether additional assumptions are warranted\n",
        "\n",
        "Testability permits us to determine whether the assumptions encoded are compatible with the available data and identify those that need repair.\n",
        "\n",
        "Transparency is done through graphs and testability is faciliated through a graphical criterion called $d$-separation."
      ],
      "metadata": {
        "id": "16-dQVNBZshA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool 2: $do$-calculus and the control of confounding"
      ],
      "metadata": {
        "id": "_opZUakOZsjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deconfounding has been demystified through a graphical criterion called \"back-door\". When backd-door does not hold, the do-calculus is available, which predicts the effect of policy interventions whenever feasible."
      ],
      "metadata": {
        "id": "5xNgANbEZslL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool 3: The Algorithmization of Counterfactuals"
      ],
      "metadata": {
        "id": "gsJ8BeH4azFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Able to formalize counterfactual reasoning within the graphical representation. Every structural equation model determines the truth value of every counterfactual sentence."
      ],
      "metadata": {
        "id": "AHAh-veDazHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool 4: Mediation Analysis and the Assessment of Direct and Indirect Effects"
      ],
      "metadata": {
        "id": "F2p6cERcazM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typical queries answerable by this analysis are: What fraction of the effect of $X$ on $Y$ is mediated by variable $Z$?"
      ],
      "metadata": {
        "id": "cCJEiktHbUVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool 5: Adaptability, External Validity and Sample Selection Bias"
      ],
      "metadata": {
        "id": "h2alm1CgbUXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A machine trained in one environment cannot be expected to perform well when environmental conditions change, unless the changes are localized and identified. This problem have manifested fields such as \"domain adaptation\", \"transfer learning\", \"life-long learning\", and \"explainable AI\". This inherently requires a causal model."
      ],
      "metadata": {
        "id": "vs8xIMnObz1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool 6: Recovering from Missing Data"
      ],
      "metadata": {
        "id": "pL8LHRn-bz3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using causal models of the missingness process we can now formalize the conditions under which causal and probabilistic relationships can be recovered from incomplete data and, whenever the conditions are satisfied, produce a consistent estimate of the desired relationship."
      ],
      "metadata": {
        "id": "_5_ZlYNjcTep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool 7: Causal Discovery"
      ],
      "metadata": {
        "id": "Dr7Ox3qwcTgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A broader field of causality in which causal graphs are recovered from data (whenever possible), enabling the identification and estimation of causal effects."
      ],
      "metadata": {
        "id": "6uPcZf2jdF9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZKWcYobmdF_8"
      }
    }
  ]
}