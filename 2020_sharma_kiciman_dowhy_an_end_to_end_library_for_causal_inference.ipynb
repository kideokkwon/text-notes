{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/EQJRISffxTH482kseKYn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# (Sharma and Kiciman, 2020) DoWhy: An End-to-End Library for Causal Inference"
      ],
      "metadata": {
        "id": "w-CwEDS3WOcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/pdf/2011.04216.pdf"
      ],
      "metadata": {
        "id": "heTEfCAHWOf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract"
      ],
      "metadata": {
        "id": "-jsjpPt1WOi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most libraries for causal inference focus on the task of providing powerful statistical estimators. DoWhy is an open-source library that is built with causal assumptions as its first-class citizens, based on the formal framework of causal graphs to specify and test causal assumptions.\n",
        "\n",
        "DoWhy presents an API for the 4 steps common to any causal analysis:\n",
        "1. **modeling** the data using a causal graph and structural assumptions\n",
        "2. **identifying** whether the desired effect is estimable under the causal model\n",
        "3. **estimating** the effect using statistical estimators\n",
        "4. **refuting** the obtained estimate through robustness checks and sensitivity analyses.\n",
        "\n",
        "DoWhy implements a number of robustness checks including placebo tests, bootstrap tests, and tests for unobserved confounding. DoWhy is an extensible library that supports interoperability with other implementations such as EconML and CausalML for the estimation step.\n"
      ],
      "metadata": {
        "id": "b-nO5Xl0WXhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction"
      ],
      "metadata": {
        "id": "Mb3RqCnLWXjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike supervised machine learning models that can be validated using held-out test data, causal tasks often have no ground truth answer available. Thus, checking core assumptions and applying sensitivity tests is critical to gaining confidence in results.\n",
        "\n",
        "*But how to check those assumptions?*\n",
        "\n",
        "Builds on the latest research in modeling assumptions and robustness checks (Athey and Imbens, 2017; Kiciman and Sharma, 2018)\n",
        "\n",
        "DoWhy builds on two of the most powerfu frameworks for causal inference: graphical models (Pearl, 2009) and potential outcomes (Imbens and Rubin, 2015). It uses graph-based criteria and do-calculus for modeling assumptions and identifying a non-parametric causal effect. For estimation, it switches to methods based primarily on potential outcomes.\n",
        "\n",
        "The library makes 3 key contributions:\n",
        "1. Provides a principled way of modeling a given problem as a causal graph so that all assumptions are explicit, and identifying a desired causal effect\n",
        "2. Provides a unified interface for many popular causal inference *estimation* methods, combining the two major frameworks of graphical models and potential outcomes.\n",
        "3. Automatically tests for the validity of causal assumptions if possible and assesses the robustness of the estimate to violations"
      ],
      "metadata": {
        "id": "AfBvkTXmWXll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. DoWhy and the Four steps of Causal Inference"
      ],
      "metadata": {
        "id": "lqo-1twPXRDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almost all causal inference methods follow four key steps:\n",
        "1. **Model the causal question**: DoWhy creates an underlying causal grpahical model for each problem. This serves to make each causal assumption explicit. The graph does not need to be complete.\n",
        "2. **Identify the causal estimand**: Finds all possible ways of identifying a desired causal effect based on the graphical model. It uses graph-based criteria and do-calculus to find potential ways to find expressions that can identify the causal effect. Supported identification criteria are:\n",
        "  - Back-door criterion\n",
        "  - Front-door criterion\n",
        "  - Instrumental Variables\n",
        "  - Mediation (Direct and indirect effect identification)\n",
        "3. **Estimate the causal effect**: DoWhy supports methods based on both back-door criterion and instrumental variables. It also provides a non-parametric confidence intervals and a permutation test for testing the statistical significance of obtained estimate. Supported estimation methods include,\n",
        "  - methods based on estimating the treatment assignment: propensity-based stratification, propensity score matching, inverse propensity weighting\n",
        "  - methods based on estimating the outcome model: linear regression, GLM\n",
        "  - methods based on the instrumental variables identification: binary instrument/wald estimator, two-stage least squares, regression discontinuity\n",
        "  - methods for front-door criterion and general mediation: two-stage linear regression\n",
        "\n",
        "In addition, all estimators from these libraries can be directly called from DoWhy.\n",
        "\n",
        "4. **Refute the obtained estimate**: Supported refutation methods include:\n",
        "  - add random common cause\n",
        "  - placebo treatment\n",
        "  - dummy outcome\n",
        "  - simulated outcome\n",
        "  - add unobserved common cause\n",
        "  - data subsets validation\n",
        "  - bootstrap validation"
      ],
      "metadata": {
        "id": "u-kcWrrcXRFt"
      }
    }
  ]
}